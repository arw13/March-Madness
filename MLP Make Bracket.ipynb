{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Data_Organization.ipynb\n",
      "Final\n",
      "Final_Data_Organization.ipynb\n",
      "Final MLP.ipynb\n",
      "GiantKillerInfo.txt\n",
      "logs\n",
      "MarchMadnessAdvStats.csv\n",
      "MarchMadnessFeatureDifferences.csv\n",
      "MarchMadnessFeatures.csv\n",
      "MarchMadnessTest.csv\n",
      "MLP Make Bracket.ipynb\n",
      "ModelEvaluation.ipynb\n",
      "OldNbs\n",
      "README.md\n",
      "SubmissionData.py\n",
      "Submissions\n",
      "tENSORFLOW.ipynb\n",
      "tENSORFLOW.py\n",
      "tENSORFLOW-TB.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras import regularizers, optimizers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../March-Madness\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-organized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../March-Madness/'\n",
    "df_features = pd.read_csv(data_dir + 'MarchMadnessFeatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector dimension is: 34.00\n"
     ]
    }
   ],
   "source": [
    "X = df_features.iloc[:,1:]\n",
    "xDim = np.shape(X)[1]\n",
    "X_train = X.values.reshape(-1,xDim)\n",
    "y_train = df_features.Result.values\n",
    "\n",
    "print('Feature vector dimension is: %.2f' % xDim)\n",
    "# print(X[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xDim = np.shape(X_train)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(data_dir+'MarchMadnessTest.csv')\n",
    "\n",
    "X_test = df_test.iloc[:,1:]\n",
    "xDimTest = np.shape(X_test)[1]\n",
    "X_test = X_test.values.reshape(-1,xDimTest)\n",
    "y_test = df_test.Result.values\n",
    "\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kfold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropRate = 0.3\n",
    "numBatch = 50\n",
    "numEpoch = 120\n",
    "learningRate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Single Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "MLP = Sequential()\n",
    "MLP.name = 'MLP'\n",
    "MLP.add(Dense(20, input_dim=xDim, kernel_initializer='glorot_normal',activation = 'tanh'))\n",
    "MLP.add(Dropout(dropRate))\n",
    "MLP.add(Dense(200,kernel_initializer='glorot_normal',activation = 'tanh'))\n",
    "MLP.add(Dropout(dropRate))\n",
    "MLP.add(Dense(200, kernel_initializer='glorot_normal',activation = 'tanh'))\n",
    "MLP.add(Dropout(dropRate))\n",
    "MLP.add(Dense(1, kernel_initializer='glorot_normal', activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "adam = optimizers.Adam(lr=learningRate, amsgrad=True)\n",
    "sgd = optimizers.SGD(lr=learningRate)\n",
    "MLP.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "530/530 [==============================] - 1s 1ms/step - loss: 0.2486 - acc: 0.5604\n",
      "Epoch 2/120\n",
      "530/530 [==============================] - 0s 60us/step - loss: 0.2299 - acc: 0.6170\n",
      "Epoch 3/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2257 - acc: 0.6509\n",
      "Epoch 4/120\n",
      "530/530 [==============================] - 0s 52us/step - loss: 0.2240 - acc: 0.6226\n",
      "Epoch 5/120\n",
      "530/530 [==============================] - 0s 57us/step - loss: 0.2210 - acc: 0.6547\n",
      "Epoch 6/120\n",
      "530/530 [==============================] - 0s 56us/step - loss: 0.2269 - acc: 0.6453\n",
      "Epoch 7/120\n",
      "530/530 [==============================] - 0s 60us/step - loss: 0.2200 - acc: 0.6566\n",
      "Epoch 8/120\n",
      "530/530 [==============================] - 0s 64us/step - loss: 0.2190 - acc: 0.6623\n",
      "Epoch 9/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2206 - acc: 0.6717\n",
      "Epoch 10/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2232 - acc: 0.6472\n",
      "Epoch 11/120\n",
      "530/530 [==============================] - 0s 56us/step - loss: 0.2289 - acc: 0.6585\n",
      "Epoch 12/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2226 - acc: 0.6585\n",
      "Epoch 13/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2191 - acc: 0.6585\n",
      "Epoch 14/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2206 - acc: 0.6585\n",
      "Epoch 15/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2193 - acc: 0.6679\n",
      "Epoch 16/120\n",
      "530/530 [==============================] - 0s 52us/step - loss: 0.2295 - acc: 0.6528\n",
      "Epoch 17/120\n",
      "530/530 [==============================] - 0s 50us/step - loss: 0.2264 - acc: 0.6736\n",
      "Epoch 18/120\n",
      "530/530 [==============================] - 0s 61us/step - loss: 0.2179 - acc: 0.6717\n",
      "Epoch 19/120\n",
      "530/530 [==============================] - 0s 59us/step - loss: 0.2252 - acc: 0.6698\n",
      "Epoch 20/120\n",
      "530/530 [==============================] - 0s 60us/step - loss: 0.2226 - acc: 0.6679\n",
      "Epoch 21/120\n",
      "530/530 [==============================] - 0s 57us/step - loss: 0.2229 - acc: 0.6642\n",
      "Epoch 22/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2195 - acc: 0.6736\n",
      "Epoch 23/120\n",
      "530/530 [==============================] - 0s 50us/step - loss: 0.2233 - acc: 0.6509\n",
      "Epoch 24/120\n",
      "530/530 [==============================] - 0s 61us/step - loss: 0.2181 - acc: 0.6623\n",
      "Epoch 25/120\n",
      "530/530 [==============================] - 0s 62us/step - loss: 0.2216 - acc: 0.6604\n",
      "Epoch 26/120\n",
      "530/530 [==============================] - 0s 62us/step - loss: 0.2178 - acc: 0.6547\n",
      "Epoch 27/120\n",
      "530/530 [==============================] - 0s 59us/step - loss: 0.2204 - acc: 0.6792\n",
      "Epoch 28/120\n",
      "530/530 [==============================] - 0s 63us/step - loss: 0.2206 - acc: 0.6679\n",
      "Epoch 29/120\n",
      "530/530 [==============================] - 0s 62us/step - loss: 0.2261 - acc: 0.6472\n",
      "Epoch 30/120\n",
      "530/530 [==============================] - 0s 75us/step - loss: 0.2239 - acc: 0.6642\n",
      "Epoch 31/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2159 - acc: 0.6717\n",
      "Epoch 32/120\n",
      "530/530 [==============================] - 0s 62us/step - loss: 0.2215 - acc: 0.6434\n",
      "Epoch 33/120\n",
      "530/530 [==============================] - 0s 56us/step - loss: 0.2165 - acc: 0.6717\n",
      "Epoch 34/120\n",
      "530/530 [==============================] - 0s 61us/step - loss: 0.2187 - acc: 0.6566\n",
      "Epoch 35/120\n",
      "530/530 [==============================] - 0s 66us/step - loss: 0.2104 - acc: 0.6566\n",
      "Epoch 36/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2147 - acc: 0.6660\n",
      "Epoch 37/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2250 - acc: 0.6358\n",
      "Epoch 38/120\n",
      "530/530 [==============================] - 0s 44us/step - loss: 0.2203 - acc: 0.6623\n",
      "Epoch 39/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2159 - acc: 0.6868\n",
      "Epoch 40/120\n",
      "530/530 [==============================] - 0s 55us/step - loss: 0.2148 - acc: 0.6698\n",
      "Epoch 41/120\n",
      "530/530 [==============================] - 0s 56us/step - loss: 0.2250 - acc: 0.6453\n",
      "Epoch 42/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2181 - acc: 0.6698\n",
      "Epoch 43/120\n",
      "530/530 [==============================] - 0s 63us/step - loss: 0.2144 - acc: 0.6792\n",
      "Epoch 44/120\n",
      "530/530 [==============================] - 0s 52us/step - loss: 0.2191 - acc: 0.6849\n",
      "Epoch 45/120\n",
      "530/530 [==============================] - 0s 57us/step - loss: 0.2215 - acc: 0.6604\n",
      "Epoch 46/120\n",
      "530/530 [==============================] - 0s 50us/step - loss: 0.2187 - acc: 0.6547\n",
      "Epoch 47/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2180 - acc: 0.6774\n",
      "Epoch 48/120\n",
      "530/530 [==============================] - 0s 64us/step - loss: 0.2210 - acc: 0.6736\n",
      "Epoch 49/120\n",
      "530/530 [==============================] - 0s 58us/step - loss: 0.2172 - acc: 0.6585\n",
      "Epoch 50/120\n",
      "530/530 [==============================] - 0s 60us/step - loss: 0.2125 - acc: 0.6849\n",
      "Epoch 51/120\n",
      "530/530 [==============================] - 0s 66us/step - loss: 0.2231 - acc: 0.6642\n",
      "Epoch 52/120\n",
      "530/530 [==============================] - 0s 58us/step - loss: 0.2132 - acc: 0.6792\n",
      "Epoch 53/120\n",
      "530/530 [==============================] - 0s 56us/step - loss: 0.2225 - acc: 0.6604\n",
      "Epoch 54/120\n",
      "530/530 [==============================] - 0s 52us/step - loss: 0.2212 - acc: 0.6509\n",
      "Epoch 55/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2206 - acc: 0.6491\n",
      "Epoch 56/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2159 - acc: 0.6642\n",
      "Epoch 57/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2239 - acc: 0.6528\n",
      "Epoch 58/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2219 - acc: 0.6642\n",
      "Epoch 59/120\n",
      "530/530 [==============================] - 0s 50us/step - loss: 0.2229 - acc: 0.6679\n",
      "Epoch 60/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2220 - acc: 0.6472\n",
      "Epoch 61/120\n",
      "530/530 [==============================] - 0s 54us/step - loss: 0.2158 - acc: 0.6642\n",
      "Epoch 62/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2187 - acc: 0.6868\n",
      "Epoch 63/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2272 - acc: 0.6547\n",
      "Epoch 64/120\n",
      "530/530 [==============================] - 0s 52us/step - loss: 0.2154 - acc: 0.6717\n",
      "Epoch 65/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2212 - acc: 0.6642\n",
      "Epoch 66/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2120 - acc: 0.6642\n",
      "Epoch 67/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2110 - acc: 0.6792\n",
      "Epoch 68/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2119 - acc: 0.6811\n",
      "Epoch 69/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2196 - acc: 0.6698\n",
      "Epoch 70/120\n",
      "530/530 [==============================] - 0s 45us/step - loss: 0.2200 - acc: 0.6547\n",
      "Epoch 71/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2188 - acc: 0.6509\n",
      "Epoch 72/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2163 - acc: 0.6755\n",
      "Epoch 73/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2223 - acc: 0.6660\n",
      "Epoch 74/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2145 - acc: 0.6811\n",
      "Epoch 75/120\n",
      "530/530 [==============================] - 0s 58us/step - loss: 0.2138 - acc: 0.6755\n",
      "Epoch 76/120\n",
      "530/530 [==============================] - 0s 55us/step - loss: 0.2171 - acc: 0.6660\n",
      "Epoch 77/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2126 - acc: 0.6943\n",
      "Epoch 78/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2107 - acc: 0.6755\n",
      "Epoch 79/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2140 - acc: 0.6868\n",
      "Epoch 80/120\n",
      "530/530 [==============================] - 0s 45us/step - loss: 0.2131 - acc: 0.6774\n",
      "Epoch 81/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2160 - acc: 0.6755\n",
      "Epoch 82/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2210 - acc: 0.6849\n",
      "Epoch 83/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2176 - acc: 0.6585\n",
      "Epoch 84/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530/530 [==============================] - 0s 51us/step - loss: 0.2144 - acc: 0.6679\n",
      "Epoch 85/120\n",
      "530/530 [==============================] - 0s 55us/step - loss: 0.2096 - acc: 0.6792\n",
      "Epoch 86/120\n",
      "530/530 [==============================] - 0s 50us/step - loss: 0.2143 - acc: 0.6774\n",
      "Epoch 87/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2163 - acc: 0.6755\n",
      "Epoch 88/120\n",
      "530/530 [==============================] - 0s 45us/step - loss: 0.2191 - acc: 0.6642\n",
      "Epoch 89/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2158 - acc: 0.6623\n",
      "Epoch 90/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2172 - acc: 0.6717\n",
      "Epoch 91/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2144 - acc: 0.6717\n",
      "Epoch 92/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2176 - acc: 0.6755\n",
      "Epoch 93/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2153 - acc: 0.6698\n",
      "Epoch 94/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2160 - acc: 0.6642\n",
      "Epoch 95/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2163 - acc: 0.6698\n",
      "Epoch 96/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2157 - acc: 0.6755\n",
      "Epoch 97/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2155 - acc: 0.6906\n",
      "Epoch 98/120\n",
      "530/530 [==============================] - 0s 53us/step - loss: 0.2117 - acc: 0.6698\n",
      "Epoch 99/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2125 - acc: 0.6792\n",
      "Epoch 100/120\n",
      "530/530 [==============================] - 0s 45us/step - loss: 0.2109 - acc: 0.6642\n",
      "Epoch 101/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2178 - acc: 0.6585\n",
      "Epoch 102/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2160 - acc: 0.6811\n",
      "Epoch 103/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2166 - acc: 0.6717\n",
      "Epoch 104/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2187 - acc: 0.6868\n",
      "Epoch 105/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2146 - acc: 0.6887\n",
      "Epoch 106/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2164 - acc: 0.6811\n",
      "Epoch 107/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2128 - acc: 0.6981\n",
      "Epoch 108/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2117 - acc: 0.6792\n",
      "Epoch 109/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2156 - acc: 0.6755\n",
      "Epoch 110/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2172 - acc: 0.6717\n",
      "Epoch 111/120\n",
      "530/530 [==============================] - 0s 45us/step - loss: 0.2200 - acc: 0.6811\n",
      "Epoch 112/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2115 - acc: 0.6698\n",
      "Epoch 113/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2166 - acc: 0.6717\n",
      "Epoch 114/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2119 - acc: 0.6660\n",
      "Epoch 115/120\n",
      "530/530 [==============================] - 0s 49us/step - loss: 0.2176 - acc: 0.6679\n",
      "Epoch 116/120\n",
      "530/530 [==============================] - 0s 46us/step - loss: 0.2144 - acc: 0.6849\n",
      "Epoch 117/120\n",
      "530/530 [==============================] - 0s 48us/step - loss: 0.2128 - acc: 0.6830\n",
      "Epoch 118/120\n",
      "530/530 [==============================] - 0s 47us/step - loss: 0.2119 - acc: 0.6849\n",
      "Epoch 119/120\n",
      "530/530 [==============================] - 0s 51us/step - loss: 0.2131 - acc: 0.6585\n",
      "Epoch 120/120\n",
      "530/530 [==============================] - 0s 45us/step - loss: 0.2117 - acc: 0.6981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f493e8c60f0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.fit(X_train, y_train, epochs=numEpoch, batch_size=numBatch, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402/402 [==============================] - 0s 723us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18164074183696538, 0.7462686561233368]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fore = RandomForestClassifier(criterion='entropy', n_estimators = 50, max_depth = 4, oob_score=True)\n",
    "\n",
    "fore.fit(X_train, y_train)\n",
    "\n",
    "y_pred =  fore.predict_proba(X_train)[:,1].reshape(-1,1)\n",
    "LL = log_loss( y_train, y_pred)\n",
    "print(\"Training set score: {:4}\" .format(LL))\n",
    "y_pred =  fore.predict_proba(X_test)[:,1].reshape(-1,1)\n",
    "LL = log_loss( y_test, y_pred)\n",
    "print(\"Validation set score: {:4}\".format(LL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.736318407960199\n"
     ]
    }
   ],
   "source": [
    "accTest = fore.score(X_test, y_test)\n",
    "print(\"Validation accuracy: {:4}\".format(accTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../March-Madness/Final/'\n",
    "df_sample_sub = pd.read_csv(data_dir + 'SampleSubmissionStage2.csv')\n",
    "data_file = data_dir + 'MarchMadnessAdvStats.csv'\n",
    "df_adv = pd.read_csv(data_file)\n",
    "df_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\n",
    "\n",
    "\n",
    "n_test_games = len(df_sample_sub)\n",
    "\n",
    "def get_year_t1_t2(ID):\n",
    "    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n",
    "    return (int(x) for x in ID.split('_'))\n",
    "\n",
    "def seed_to_int(seed):\n",
    "    '''Get just the digits from the seeding. Return as int'''\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for submission test\n"
     ]
    }
   ],
   "source": [
    "print('Loading data for submission test')\n",
    "\n",
    "# Make the seeding an integer\n",
    "df_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\n",
    "df_seeds.drop(columns=['Seed'], inplace=True) # This is the string label\n",
    "df_seeds.head()\n",
    "\n",
    "\n",
    "T1_seed = []\n",
    "T1_adv = []\n",
    "T2_adv = []\n",
    "T2_seed = []\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, t1, t2 = get_year_t1_t2(row.ID)\n",
    "    t1_seed = df_seeds[(df_seeds.TeamID == t1) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    t2_seed = df_seeds[(df_seeds.TeamID == t2) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    t1_adv = df_adv[(df_adv.TeamID == t1) & (df_adv.Season == year)].values[0]\n",
    "    t2_adv = df_adv[(df_adv.TeamID == t2) & (df_adv.Season == year)].values[0]\n",
    "    T1_seed.append(t1_seed)\n",
    "    T1_adv.append(t1_adv)\n",
    "    T2_seed.append(t2_seed)\n",
    "    T2_adv.append(t2_adv)\n",
    "\n",
    "T1_adv = [row[2:] for row in T1_adv]\n",
    "T2_adv = [row[2:] for row in T2_adv]\n",
    "T1_seed = np.reshape(T1_seed, [n_test_games,-1]).tolist()\n",
    "T2_seed = np.reshape(T2_seed, [n_test_games, -1]).tolist()\n",
    "X_pred = np.concatenate((T1_seed, T1_adv, T2_seed, T2_adv), axis=1)\n",
    "\n",
    "df_subData = pd.DataFrame(np.array(X_pred).reshape(np.shape(X_pred)[0], np.shape(X_pred)[1]))\n",
    "\n",
    "xDim = np.shape(df_subData)[1]\n",
    "X_pred = df_subData.values.reshape(-1,xDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278, 34)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = pca.transform(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2278, 2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = MLP.predict(X_pred)\n",
    "\n",
    "# df_sample_sub = pd.DataFrame()\n",
    "# clipped_preds = np.clip(preds, 0.05, 0.95)\n",
    "df_sample_sub.Pred = preds\n",
    "df_sample_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-50e7733b95f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df_sample_sub = pd.DataFrame()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# clipped_preds = np.clip(preds, 0.05, 0.95)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_sample_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fore' is not defined"
     ]
    }
   ],
   "source": [
    "preds = fore.predict(X_pred)\n",
    "\n",
    "# df_sample_sub = pd.DataFrame()\n",
    "# clipped_preds = np.clip(preds, 0.05, 0.95)\n",
    "df_sample_sub.Pred = preds\n",
    "df_sample_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'makeBrack'\n",
    "save_dir = '../March-Madness/Final/'\n",
    "c=0\n",
    "ext = '.csv'\n",
    "if os.path.exists(save_dir+filename+ext):\n",
    "    while os.path.exists(filename+ext):\n",
    "        c+=1\n",
    "    filename = filename+'_'+str(c)\n",
    "    df_sample_sub.to_csv(save_dir+filename+ext, index=False)\n",
    "else:\n",
    "    df_sample_sub.to_csv(save_dir+filename+ext, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
