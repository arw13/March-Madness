{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ec7cb961-f53c-472b-9a15-6e92b0296082",
    "_uuid": "9853586a0dc75ce39e7c7ffcde1eb4d47c6fb02e"
   },
   "source": [
    "# Keras MLP \n",
    "## Overview ##\n",
    "This kernel uses seeding and relative seeding with an MLP network. Spread on loss was very small, so kfold not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0c233e05-c63d-4866-96dc-bb38d444bf84",
    "_uuid": "5464dc4b196dc4c8dd0323bbd71b75724113e2af"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from time import localtime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ProgbarLogger\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../NCAA\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lock Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11333bea-8d7c-47b2-b24b-97a8f38db6ae",
    "_uuid": "819472385a23f3fd5aaf4172b4f8db227cf5271f"
   },
   "source": [
    "# Load and Organize Training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ec1d5ab6-5977-4246-b355-8afd9101a405",
    "_uuid": "bf8ee168a0372e883332d6bb0ce5c89c13143650"
   },
   "outputs": [],
   "source": [
    "data_dir = '../NCAA/Data/'\n",
    "df_seeds = pd.read_csv(data_dir + 'NCAATourneySeeds.csv')\n",
    "df_tour = pd.read_csv(data_dir + 'NCAATourneyCompactResults.csv')\n",
    "df_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporate Massey Ordinals - MAS, SAG, POM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "df_rank = pd.read_csv(data_dir+ 'MasseyOrdinals.csv')\n",
    "#Choose Latest Ranking \n",
    "df_rank = df_rank[df_rank.RankingDayNum>=133]\n",
    "df_rank = df_rank[df_rank.Season>=2010]\n",
    "\n",
    "#Selectr rankings of interest and make each ranking system ranking into a separate column\n",
    "df_merge = pd.merge(df_rank.loc[df_rank['SystemName']=='MAS'],\n",
    "                    df_rank.loc[df_rank['SystemName']=='SAG'], how='left', \n",
    "                    on=['Season', 'TeamID', 'RankingDayNum'])\n",
    "df_rank = pd.merge(left=df_merge, right=df_rank.loc[df_rank['SystemName']=='POM'], \n",
    "                  how='left', on=['Season', 'TeamID', 'RankingDayNum'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "df_rank.drop(labels=['SystemName_x', 'SystemName_y', 'SystemName','RankingDayNum'], inplace=True, axis =1)\n",
    "df_rank.rename(columns={'OrdinalRank_x':'MAS', 'OrdinalRank_y':'SAG', 'OrdinalRank':'POM'}, inplace=True)\n",
    "\n",
    "# df_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add advanced stats from https://www.kaggle.com/lnatml/feature-engineering-with-advanced-stats/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/NCAATourneyDetailedResults.csv')\n",
    "\n",
    "#Points Winning/Losing Team\n",
    "df_adv['WPts'] = df.apply(lambda row: 2*(row.WFGM-row.WFGM3) + 3*row.WFGM3 + row.WFTM, axis=1)\n",
    "df_adv['LPts'] = df.apply(lambda row: 2*(row.LFGM-row.WFGM3) + 3*row.LFGM3 + row.LFTM, axis=1)\n",
    "\n",
    "#Calculate Winning/losing Team Possesion Feature\n",
    "wPos = df.apply(lambda row: 0.96*(row.WFGA + row.WTO + 0.44*row.WFTA - row.WOR), axis=1)\n",
    "lPos = df.apply(lambda row: 0.96*(row.LFGA + row.LTO + 0.44*row.LFTA - row.LOR), axis=1)\n",
    "#two teams use almost the same number of possessions in a game\n",
    "#(plus/minus one or two - depending on how quarters end)\n",
    "#so let's just take the average\n",
    "df_adv['Pos'] = (wPos+lPos)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Offensive efficiency (OffRtg) = 100 x (Points / Possessions)\n",
    "df_adv['WOffRtg'] = df.apply(lambda row: 100 * (row.WPts / row.Pos), axis=1)\n",
    "df_adv['LOffRtg'] = df.apply(lambda row: 100 * (row.LPts / row.Pos), axis=1)\n",
    "#Defensive efficiency (DefRtg) = 100 x (Opponent points / Opponent possessions)\n",
    "df_adv['WDefRtg'] = df.LOffRtg\n",
    "df_adv['LDefRtg'] = df.WOffRtg\n",
    "#Net Rating = Off.eff - Def.eff\n",
    "df_adv['WNetRtg'] = df.apply(lambda row:(row.WOffRtg - row.LDefRtg), axis=1)\n",
    "df_adv['LNetRtg'] = df.apply(lambda row:(row.LOffRtg - row.LDefRtg), axis=1)\n",
    "                         \n",
    "#Assist Ratio : Percentage of team possessions that end in assists\n",
    "df_adv['WAstR'] = df.apply(lambda row: 100 * row.WAst / (row.WFGA + 0.44*row.WFTA + row.WAst + row.WTO), axis=1)\n",
    "df_adv['LAstR'] = df.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "#Turnover Ratio: Number of turnovers of a team per 100 possessions used.\n",
    "#(TO * 100) / (FGA + (FTA * 0.44) + AST + TO\n",
    "df_adv['WTOR'] = df.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "df_adv['LTOR'] = df.apply(lambda row: 100 * row.LAst / (row.LFGA + 0.44*row.LFTA + row.LAst + row.LTO), axis=1)\n",
    "                    \n",
    "#The Shooting Percentage : Measure of Shooting Efficiency (FGA/FGA3, FTA)\n",
    "df_adv['WTSP'] = df.apply(lambda row: 100 * row.WPts / (2 * (row.WFGA + 0.44 * row.WFTA)), axis=1)\n",
    "df_adv['LTSP'] = df.apply(lambda row: 100 * row.LPts / (2 * (row.LFGA + 0.44 * row.LFTA)), axis=1)\n",
    "#eFG% : Effective Field Goal Percentage adjusting for the fact that 3pt shots are more valuable \n",
    "df_adv['WeFGP'] = df.apply(lambda row:(row.WFGM + 0.5 * row.WFGM3) / row.WFGA, axis=1)      \n",
    "df_adv['LeFGP'] = df.apply(lambda row:(row.LFGM + 0.5 * row.LFGM3) / row.LFGA, axis=1)   \n",
    "#FTA Rate : How good a team is at drawing fouls.\n",
    "df_adv['WFTAR'] = df.apply(lambda row: row.WFTA / row.WFGA, axis=1)\n",
    "df_adv['LFTAR'] = df.apply(lambda row: row.LFTA / row.LFGA, axis=1)\n",
    "                         \n",
    "#OREB% : Percentage of team offensive rebounds\n",
    "df_adv['WORP'] = df.apply(lambda row: row.WOR / (row.WOR + row.LDR), axis=1)\n",
    "df_adv['LORP'] = df.apply(lambda row: row.LOR / (row.LOR + row.WDR), axis=1)\n",
    "#DREB% : Percentage of team defensive rebounds\n",
    "df_adv['WDRP'] = df.apply(lambda row: row.WDR / (row.WDR + row.LOR), axis=1)\n",
    "df_adv['LDRP'] = df.apply(lambda row: row.LDR / (row.LDR + row.WOR), axis=1)                                      \n",
    "#REB% : Percentage of team total rebounds\n",
    "df_adv['WRP'] = df.apply(lambda row: (row.WDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1)\n",
    "df_adv['LRP'] = df.apply(lambda row: (row.LDR + row.WOR) / (row.WDR + row.WOR + row.LDR + row.LOR), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cut seasons prior to Max Ranking date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ec1d5ab6-5977-4246-b355-8afd9101a405",
    "_uuid": "bf8ee168a0372e883332d6bb0ce5c89c13143650"
   },
   "outputs": [],
   "source": [
    "df_seeds = df_seeds[df_seeds.Season>=min(df_rank.Season) ]\n",
    "df_seeds = df_seeds[ df_seeds.Season<=max(df_rank.Season)]\n",
    "df_tour = df_tour[df_tour.Season>=min(df_rank.Season)]\n",
    "df_tour = df_tour[ df_tour.Season<=max(df_rank.Season)]\n",
    "# df_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79186b24-985b-40da-8ae6-f4f4b44f05a2",
    "_uuid": "42f99f53dd385e23b09378e0de9d3fce5eb1a2e9"
   },
   "source": [
    "Cut off the region identifier from the seed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da1a44b9-1a31-4fbb-bcaf-e18bd9585e13",
    "_uuid": "fcb18269a41cfa257bd97c40664e43e701251bed"
   },
   "outputs": [],
   "source": [
    "def seed_to_int(seed):\n",
    "    #Get just the digits from the seeding. Return as int\n",
    "    s_int = int(seed[1:3])\n",
    "    return s_int\n",
    "df_seeds['seed_int'] = df_seeds.Seed.apply(seed_to_int)\n",
    "df_seeds.drop(columns=['Seed'], inplace=True) # This is the string label\n",
    "\n",
    "df_tour.drop(labels=['DayNum', 'WScore', 'LScore','WLoc', 'NumOT'], inplace=True, axis=1)\n",
    "# df_tour.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77c94357-56ed-461b-bcbf-09fcc9fcfff7",
    "_uuid": "3f223cdf4446d6e9c77ab8319237f05393d1a822"
   },
   "source": [
    "Merge the Seeds with their corresponding TeamIDs in the compact results dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "08c9fb98-b372-408d-a748-bdbb3e50c3df",
    "_uuid": "53638c1ae27cfb24d47e02007c293d5ee19ebdac"
   },
   "outputs": [],
   "source": [
    "df_winSeeds = df_seeds.rename(columns={'TeamID':'WTeamID', 'seed_int':'WSeed'})\n",
    "df_lossSeeds = df_seeds.rename(columns={'TeamID':'LTeamID', 'seed_int':'LSeed'})\n",
    "\n",
    "\n",
    "df_dummy = pd.merge(left=df_tour, right=df_lossSeeds, how='left', on=['Season', 'LTeamID'])\n",
    "\n",
    "df_concat = pd.merge(left=df_dummy, right=df_winSeeds, how='left' ,on=['Season', 'WTeamID'])\n",
    "# df_concat['SeedDiff'] = df_concat.WSeed - df_concat.LSeed\n",
    "# df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f6e2a63e-3d1b-49d5-86ef-0af5b1f5294e",
    "_uuid": "1c82f60c02545c8c46ab090cb8cefca48e48e434"
   },
   "source": [
    " Make a winner and loser DF with seed, relative seed, and win/loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins = pd.DataFrame()\n",
    "df_wins['Seed'] = df_concat['WSeed']\n",
    "# df_wins['SeedDiff'] = df_concat['SeedDiff']\n",
    "df_wins['TeamID'] = df_concat['WTeamID']\n",
    "df_wins['Season'] = df_concat['Season']\n",
    "df_wins['Result'] = 1\n",
    "df_wins = pd.merge(left=df_wins, right=df_rank, how='left', on=['Season', 'TeamID'])\n",
    "# df_wins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_losses = pd.DataFrame()\n",
    "df_losses['Seed'] = df_concat['LSeed']\n",
    "# df_losses['SeedDiff'] = -df_concat['SeedDiff']\n",
    "df_losses['TeamID'] = df_concat['LTeamID']\n",
    "df_losses['Season'] = df_concat['Season']\n",
    "df_losses['Result'] = 0\n",
    "df_losses = pd.merge(left=df_losses, right=df_rank, how='left',on=['Season', 'TeamID'])\n",
    "# df_losses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefix the cols with 'Opp' in dummy frames to allow for horizontal concat in order to expand data to be\n",
    "\n",
    "| winr_stat    losr_stat |\n",
    "                     \n",
    "| losr_stat    winr_stat |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lossesOpp = df_losses.copy()\n",
    "df_lossesOpp.drop(labels=['Season', 'Result'], inplace=True, axis=1)\n",
    "new_names = [(i,'Opp'+i) for i in df_lossesOpp.columns.values]\n",
    "df_lossesOpp.rename(columns = dict(new_names), inplace=True)\n",
    "# df_lossesOpp.head()\n",
    "\n",
    "df_winsOpp = df_wins.copy()\n",
    "df_winsOpp.drop(labels=['Season', 'Result'], inplace=True, axis=1)\n",
    "new_names = [(i,'Opp'+i) for i in df_winsOpp.columns.values]\n",
    "df_winsOpp.rename(columns = dict(new_names), inplace=True)\n",
    "# df_winsOpp.head()\n",
    "\n",
    "df_winloss = pd.concat([df_wins, df_lossesOpp], axis=1)\n",
    "\n",
    "df_losswin = pd.concat([df_losses, df_winsOpp], axis=1)\n",
    "# df_losswin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine into final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fefed035-2256-414b-b985-99b4c1a9f5e1",
    "_uuid": "1a40000e85c0dd9d2be6850a767acd736bf5f182"
   },
   "outputs": [],
   "source": [
    "df_finalData = pd.concat((df_winloss, df_losswin))\n",
    "results = df_finalData['Result']\n",
    "df_finalData.drop(labels=['Result'], inplace=True, axis=1)\n",
    "df_finalData.insert(0, 'Result', results)\n",
    "# df_finalData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove team ID and season -> cannot be scaled and not a metric. Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalData.drop(labels=['TeamID', 'Season', 'OppTeamID'], inplace=True, axis=1)\n",
    "df_finalData.head()\n",
    "\n",
    "df_final.to_csv('MarchMadnessFeatures', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finalData.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit the Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_finalData.iloc[:,1:]\n",
    "xDim = np.shape(X)[1]\n",
    "X= X.values.reshape(-1,xDim)\n",
    "y = df_finalData.Result.values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "print('Feature vector dimension is: %.2f' % xDim)\n",
    "print(X[:5,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "\n",
    "fore = RandomForestClassifier(criterion='entropy', n_estimators = 20, max_depth = 4, random_state=0)\n",
    "\n",
    "fore.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvresults = cross_val_score(fore, X, y, cv=kfold ,scoring='neg_log_loss', verbose=0)\n",
    "print('Log-Loss Mean :{:.3} ({:.3})'.format(np.mean(cvresults), np.std(cvresults)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "# fig = plt.figure()\n",
    "# fig.suptitle('Algorithm Comparison')\n",
    "# plt.boxplot((cvresults))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data desired for the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "483e4e68-0c55-4272-804c-d0ff444d9d34",
    "_uuid": "cd5a427eca09adda4e9a42a88208b683020a1f8d"
   },
   "outputs": [],
   "source": [
    "df_sample_sub = pd.read_csv(data_dir + 'SampleSubmissionStage1.csv')\n",
    "n_test_games = len(df_sample_sub)\n",
    "\n",
    "def get_year_t1_t2(ID):\n",
    "    \"\"\"Return a tuple with ints `year`, `team1` and `team2`.\"\"\"\n",
    "    return (int(x) for x in ID.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ecf47049-7dd5-4e10-9c00-d563d45479b4",
    "_uuid": "72d64ebc20c903660108ae9c529be07859396909"
   },
   "outputs": [],
   "source": [
    "X_test = np.zeros(shape=(n_test_games, xDim))\n",
    "for ii, row in df_sample_sub.iterrows():\n",
    "    year, t1, t2 = get_year_t1_t2(row.ID)\n",
    "    t1_seed = df_seeds[(df_seeds.TeamID == t1) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    t2_seed = df_seeds[(df_seeds.TeamID == t2) & (df_seeds.Season == year)].seed_int.values[0]\n",
    "    diff_seed = t1_seed - t2_seed\n",
    "    X_test[ii, 0] = t1_seed\n",
    "    X_test[ii, 1] = diff_seed\n",
    "    X_test[ii, 2] = t1\n",
    "    X_test[ii, 3] = year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale data with appropriate scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a468eb6a-1d5a-47cb-ac84-26d4dddaecd5",
    "_uuid": "375748512c55520e00ffd5701c82704856478370"
   },
   "source": [
    "## Make Predictions ##\n",
    "Create predictions using the logistic regression model we trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = fore.predict_proba(X_test)\n",
    "\n",
    "clipped_preds = np.clip(preds, 0.05, 0.95)\n",
    "df_sample_sub.Pred = clipped_preds\n",
    "df_sample_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c2012af-908f-4abc-8efb-c767086a64a9",
    "_uuid": "3f4ef6ab893953a811462d240778205c2fdecf97"
   },
   "source": [
    "Lastly, create your submission file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c83cae25-3b6f-43f4-bfcb-59402b4667d7",
    "_uuid": "7c784a9b62d889e83493b70efa17bd233f9abff4"
   },
   "outputs": [],
   "source": [
    "filename = 'RandomForest_RankSeeds'\n",
    "c=0\n",
    "ext = '.csv'\n",
    "if os.path.exists(filename+ext):\n",
    "    while os.path.exists(filename+ext):\n",
    "        c+=1\n",
    "        filename = filename+'_'+str(c)\n",
    "    df_sample_sub.to_csv(filename+ext, index=False)\n",
    "else:\n",
    "    df_sample_sub.to_csv(filename+ext, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
